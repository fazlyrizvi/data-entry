{"origin_pdf_path": "https://arc.cct.ie/cgi/viewcontent.cgi?article=1054&context=ict", "text_in_pdf": "Acronymns  \n\nA Lexicalized Domain Ontology and a Regularised Neural Attention model (ALDONAr)   \nArtificial Neural Network (ANN)   \nAspect-based sentiment analysis (ABSA)   \nBidirectional Encoder Representations from Transformers (BERT)   \nCredit Default Swaps (CDS)   \nCustomer Relationship Management (CRM)   \nDistilBERT (distilled BERT)   \nFeedback Aspect-based sentiment analysis (FABSA)   \nGenerative Pre-trained Transformer (GPT)   \nHarris Hawk (HH)   \nHierarchical Attention Network (HAN)   \nLatent Semantic Analysis (LSA)   \nLatentDirichel Allocation (LDA)   \nLong Short -Term Memory (LSTM)   \nNatural Language Toolkit (NLTK)   \nMultinomial Naïve Bayes (MNB)   \nNatural Language Processing (NLP)   \nOrdinary Least Squares (OLS)   \nParts-of-Speech (PoS)   \nRecurrent Neural Network (RNN)   \nSupport Vector Machine (SVM)  \n\n2 Abstract  \n\nSentiment analysis within customer queries stems from its critical role in shaping the perception of a company’s brand.  Poor handling of customer queries may lead to adverse consequences.  This paper explored and compared the performances of NLP models, including NLTK, spaCy, BERT and DistilBERT on a dataset comprising of customer queries and feedback. The study aimed to evaluate the accuracy and effectiveness of these diverse NLP models in analysing sentiment within customer communications.  \n\nThe findings reveal distinct patterns among the models. BERT and DistilBERT exhibit greater similarity in their results, as do NLTK and spaCy. Notably, BERT and DistilBERT demonstrate a tendency to categorize queries as predominantly neutral, suggesting potential strengths in handling diverse customer sentiments. This analysis contributes valuable insights into the strengths and weaknesses of various NLP models.  \n\n3 Introduction  \n\nIn today’s customer focused environment, it is crucial to efficiently manage customers queries, feedback and expectations.  A focus on NLP models offers unmatched opportunities for automating and improving sentiment analysis in customer data.  This research compares four important NLP models: NLTK, spaCy, BERT, and DistilBERT, focusing on sentiment analysis in customer queries.  \n\nAccurate sentiment analysis in customer queries is crucial since it can immediately impact a company's reputation and brand image. Inadequately addressing consumer problems can lead to decreased customer satisfaction and brand loyalty. Understanding the intricacies of sentiment analysis models is essential for organisations looking to optimise their client interactions.  \n\nThis paper evaluates and compares the outcomes of each NLP model. The findings show that BERT and DistilBERT produce similar results, while NLTK and spaCy follow a comparable pattern, prompting a closer look at the strengths and weaknesses of these models. Particularly, the prevalence of neutral sentiments in BERT and DistilBERT's analysed queries suggests potential advantages in capturing diverse customer sentiment. The subsequent sections delve into the methodologies, dataset, and a comprehensive discussion of the comparative results, offering valuable insights for businesses seeking effective sentiment analysis strategies in customer queries.  \n\nResearch problem and objective  \n\n4.1 Research Overview  \n\nSentiment analysis has become a crucial aspect of understanding customer feedback and opinions, providing valuable insights for businesses. This research aims to conduct a comprehensive comparison of sentiment analysis results on a dataset comprising customer queries. The study focuses on leveraging state-of-the-art NLP tools, including spaCy, NLTK, BERT, and DistilBERT to evaluate the polarity of each customer query.  \n\nThe selected dataset consists of diverse customer queries, capturing a range of sentiments expressed by users. The goal is to assess the effectiveness and distinctions of sentiment analysis across these different NLP frameworks and models, shedding light on their respective strengths and limitations.  \n\n4.2 Research Objectives  \n\n4.2.1 Evaluate Performance  \n\nAssess the accuracy and efficiency of sentiment analysis using spaCy, NLTK, BERT, and DistilBERT on the customer query dataset.  \n\nAnalyse the strengths and weaknesses of each tool in identifying sentiment polarity, considering factors such as context, complexity, and language nuances.  \n\n4.2.2 Compare Algorithmic Approaches  \n\nCompare the underlying algorithms and methodologies employed by spaCy, NLTK, BERT, and DistilBERT) in sentiment analysis.  \n\nInvestigate how each approach handles sentiment classification tasks and understand their respective mechanisms.  \n\n4.2.3  Provide Comparative Insights  \n\nOffer a comprehensive comparison and contrast of sentiment analysis results obtained from each tool, highlighting their respective performances.  \n\nDraw conclusions on the most effective tool for sentiment analysis in the context of customer queries and identify potential areas for improvement.  \n\nThrough this research, we aim to contribute valuable insights into the performance and suitability of various NLP tools for sentiment analysis in customer feedback scenarios, assisting businesses in making informed decisions based on the unique requirements of their datasets and applications.  \n\n5 Contribution  \n\nThe contributions of this paper are the systematic evaluation and comparison of two NLP tools, spaCy and NLTK, and two deep learning models, BERT and DistilBERT, to determine the most suitable for sentiment analysis within the context of customer feedback and queries.  \n\n6 Sampling Strategy  \n\n6.1  Populations of Interest  \n\n6.1.1 Customer Queries Dataset  \n\nThe primary population of interest is a dataset of customer queries sourced from a cloudbased customer service platform and saved in a csv format. This population is representative of written customer interactions, providing a representative sample of the various queries and concerns raised by customers.  This population directly aligns with the research objectives, allowing for a focused analysis of the impact of NLP on query resolution and customer interactions.  \n\nThe sampling method for the dataset will be simple random sampling – utilising a random sampling method to extract a representative subset of written customer queries from different categories or segments within the overall dataset. This is to ensure that each query in the dataset has an equal chance of being selected which will enhance the generalisability of findings to the entire population of customer queries.  This method also minimises selection bias and ensures that a fair representation of queries is selected.  \n\n7 Primary Research, Methodology and Ethics  \n\nThe chosen research methodology involved conducting interviews with five candidates that had been carefully selected.  Two of the candidates could not be reached or communicated with and the remaining candidates were interviewed.  These included one individual with expertise in deep learning and two end users of the sentiment analysis tools or services. Among the reasons for choosing interviews as the insightful perspectives that could be gleaned.  The interviews provided an opportunity to gather insights from experts who possess in-depth knowledge, experience and nuanced perspectives in the relevant fields. This allowed for a holistic understanding of the applications, challenges and benefits of sentiment analysis.  Having engaged with experts, the research gained a better  \n\nunderstanding of specific challenges and requirements necessary for the implementation of sentiment analysis.  \n\nFor the interview process, an email was dispatched to the interviewee, articulately detailing the interview's purpose and the intended use of the gathered information. In cases where recording was contemplated, explicit permission was sought in advance through email correspondence as a verifiable record. Participants were also be briefed on the dissemination of findings and informed of their potential access to the results.  \n\nThe importance of training a deep learning model on multiple epochs and visualising the results was discussed by (Individual with expertise in deep learning, 2024).  Both end users (End User 1, 2024; End User 2, 2024) emphasized the importance of sentiment on the customer relationship as well as brand perception.  The sentiment within the customer queries that are received on their platform can be used to determine resourcing.  If the queries are not dealt with adequately this can lead to customers using alternate public platforms where negative sentiment can directly influence the brand. So while the sentiment of the customer queries may not directly affect brand perception, if not dealt with satisfactorily the implications are have increased effects. They also spoke to the importance of sentiment analysis during sales periods.  Because these are the busiest periods there is a lean towards more negative sentiment and there is a need to determine where these periods are and if the solutions are effective in reducing negative sentiment.  \n\n8 Timeframe and Supervisor Meetings  \n\nThe project timeline was from 29 November 2023 – 23 February 2024.  \n\nThe meetings with the supervisor were conducted on the dates of 06 December, 09 January, 24 January, 07 February, 13 February and 20 February.  Additional communication was done via email.  \n\nEach meeting reviewed the status of the thesis and discussed the minimum necessary steps that needed to be taken for the following meeting.  The meetings focused on the development of the code and specifically any machine learning. The continual building of the literature review included focus on using papers with high impact factor. The methodology for writing the thesis and the natural progression and evolution of the research objectives as the thesis progressed,  and the architecture of the thesis to tie all these factors together.\n\nAAnnaallyyssiinngg  NNaattuurraall  LLaanngguuaaggee  PPrroocceessssiinngg  TTeecchhnniiqquueess::  AA CCoommppaarraattiivvee  SSttuuddyy  ooff  NNLLTTKK,,  ssppaaCCyy,,  BBEERRTT,,  aanndd  DDiissttiillBBEERRTT  oonn  \n\nCCuussttoommeerr  QQuueerryy  DDaattaasseettss..  \n\nPatrizia De Camillis CCT College Dublin  \n\nFollow this and additional works at: https://arc.cct.ie/ict  \n\n  \n\nPart of the Computer Sciences Commons  \n\nAnalysing Natural Language Processing Techniques: A Comparative Study of NLTK, spaCy, BERT, and DistilBERT on Customer Query Datasets  \n\nPatrizia De Camillis  \n\nA Thesis Submitted in Partial Fulfilment  \n\nof the requirements for the  \n\nDegree of  \n\nMaster of Science in Data Analytics  \n\n1.1 Table of Contents  \n\n1.1 Table of Contents .   \n2 Abstract .. 6   \n3 Introduction .. 6   \n4 Research problem and objective . 4.1 Research Overview .... 4.2 Research Objectives ...... 4.2.1 Evaluate Performance .. 4.2.2 Compare Algorithmic Approaches ... 4.2.3  Provide Comparative Insights ....   \n5 Contribution .... 8   \n6 Sampling Strategy ... 8 6.1 Populations of Interest ..... 8 6.1.1  Customer Queries Dataset . 8   \n7 Primary Research, Methodology and Ethics ..... . 8   \n8 Timeframe and Supervisor Meetings... 9   \n9 Literature Review .... . 10 9.1 Language .. . 10 9.1.1  Sentiment analysis techniques, challenges, and opportunities: Urdu languagebased analytical study ..... . 10 9.2 Machine Learning .... . 11 9.2.1  Machine learning-based proactive social-sensor service for mental health monitoring using twitter data ........ . 11 9.2.2  Sentiment analysis for customer review: Case study of Traveloka ... 12 9.2.3  Deep Learning-based Sentiment Analysis: Establishing Customer Dimension as the Lifeblood of Business Management .. . 12 9.2.4  Sentiment Analysis for Customer Relationship Management: An Incremental Learning Approach .... . 13 9.2.5  Twitter-derived measures of sentiment towards minorities (2015–2016) and associations with low birth weight and preterm birth in the United States .... .. 14 9.2.6  Understanding public engagement on twitter using topic modelling: The 2019 Ridgecrest earthquake case .. .. 15   \n9.3 Time Series . . 16 9.3.1 An alternative approach to predicting bank credit risk in Europe with Google data 16   \n9.4 Sentiment Analysis ..... . 17 9.4.1  Impact of demography on linguistic aspects and readability of reviews and performances of sentiment classifiers .. . 17 9.4.2  Effect of Negation in Sentences on Sentiment Analysis and Polarity Detection . 18 9.4.3  Extending latent semantic analysis to manage its syntactic blindness .... . 19 9.4.4  Enriching semantic knowledge bases for opinion mining in big data applications 20   \n9.5 Sentiment Spin: Attacking Financial Sentiment with GPT-3 .. 21   \nA 2-tuple fuzzy linguistic model for recommending health care services grounded on   \naspect-based sentiment analysis ......... ... 22 9.5.1  Sentiment analysis of COVID-19 cases in Greece using Twitter data ...... .. 23   \n9.6 Deep Learning .... .. 24 9.6.1  ALDONAr: A hybrid solution for sentence-level aspect-based sentiment analysis using a lexicalized domain ontology and a regularised neural attention model ............. 24 9.6.2  Automated sentiment analysis in social media using Harris Hawks optimisation and deep learning technique .... . 24 9.6.3  A novel fusion-based deep learning model for sentiment analysis of COVID-19 tweets 25 9.6.4  FABSA: An aspect-based sentiment analysis dataset of user reviews ..... .... 26   \n0 Research framework/model .. .. 28   \n10.1 Architecture . .. 28   \n10.2 Exploratory Data Analysis . . 29   \n10.3 Preprocess Text .. . 29  \n\n10.3.1 Eliminating Rows with Non-Evaluative Content .. . 29   \n10.3.2 Language ..... .. 29   \n10.4 Natural Language Process Preprocessing . . 31   \n10.4.1 Handling Contractions .... . 31   \n10.4.2 Handling Negations ..... . 32   \n10.4.3 Remove Stopwords, Tokenize, Lemmatize . .. 32   \n10.4.4 Sentiment Analysis . . 33   \n10.5 Neural Network Models . .. 34   \n10.5.1 Choosing NN Models ... .. 34   \n10.5.2 Import Dataset .... .. 35   \n10.5.3 Preprocess Labelled Text .... .. 35   \n10.5.4 Set a random seed for reproducibility . . 35   \n10.5.5 Define your custom dataset ...... .... 35   \n10.5.6 Load your labelled dataframe ... . 36   \n10.5.7 Define training parameters .... .. 37   \n10.5.8 Fine-tune the model on labelled data .. 40   \n10.6 Use the trained model for inference on the unlabelled data . ....... 43   \n10.7 Comparing Models .... .. 44   \n1 Conclusions and Future Research . 47   \n2 Evaluation of ethical and legal issues of the project .. .. 47   \n3 Bibliography ......... .. 47   \n4 Appendix .. . 55   \n14.1 Interviews .. ..... 55   \n14.1.1 Candidate 1 - Individual with expertise in deep learning .. ...... 55   \n14.1.2 Candidate 2 - End User ...... .. 57   \n14.1.3 Candidate 3 - End User .. . 59", "files_in_pdf": [{"path": ".pdf_temp/viewrange_chunk_1_1_5_1761892358/images/rorihg.jpg", "size": 2542}]}