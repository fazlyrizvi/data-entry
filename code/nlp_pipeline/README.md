# NLP Processing Pipeline

A robust, production-ready natural language processing pipeline for intelligent data extraction and classification. Built with spaCy, NLTK, Transformers, and FastAPI.

## üöÄ Features

### Entity Extraction
- **Named Entity Recognition**: Persons, organizations, locations using spaCy
- **Pattern Matching**: Regex-based extraction for structured data
- **Multi-language Support**: English, Spanish, French, German
- **Custom Entities**: User-defined pattern recognition
- **Form Field Recognition**: Automatic form field extraction

### Data Classification
- **Document Type Classification**: Invoice, contract, resume, form, report
- **Sentiment Analysis**: Positive, negative, neutral classification
- **Entity Classification**: Advanced NER with confidence scores
- **Sensitive Information Detection**: PII, financial, contact data

### API Features
- **RESTful API**: FastAPI-based web service
- **Real-time Processing**: Sub-second response times
- **Batch Processing**: Handle multiple documents efficiently
- **File Upload Support**: Text, CSV, Excel files
- **Async Operations**: Background task processing

## üì¶ Installation

### Prerequisites
- Python 3.8 or higher
- pip package manager

### Quick Start

1. **Clone and Install**
   ```bash
   cd code/nlp_pipeline
   pip install -r requirements.txt
   ```

2. **Download Models**
   ```bash
   python -m spacy download en_core_web_sm
   python -m spacy download es_core_news_sm
   python -m spacy download fr_core_news_sm
   python -m spacy download de_core_news_sm
   ```

3. **Run Tests**
   ```bash
   python test_pipeline.py
   ```

4. **Start API Server**
   ```bash
   python main.py
   ```

   API will be available at: http://localhost:8000

## üîß Configuration

### Environment Variables
```bash
export API_HOST=0.0.0.0
export API_PORT=8000
export LOG_LEVEL=INFO
export MAX_TEXT_LENGTH=50000
```

### Model Configuration
Edit `config.py` to customize:
- spaCy models for different languages
- Transformers models for classification
- Confidence thresholds
- Batch processing settings

## üìö API Usage

### Extract Entities
```bash
curl -X POST "http://localhost:8000/extract-entities" \
     -H "Content-Type: application/json" \
     -d '{
       "text": "John Smith email: john@example.com phone: (555) 123-4567"
     }'
```

### Classify Document
```bash
curl -X POST "http://localhost:8000/classify" \
     -H "Content-Type: application/json" \
     -d '{
       "text": "Invoice #12345 for $1,500.00",
       "classification_tasks": ["document_type", "sentiment"]
     }'
```

### Extract Form Fields
```bash
curl -X POST "http://localhost:8000/extract-form-fields" \
     -H "Content-Type: application/json" \
     -d '{
       "text": "Name: John Smith\\nEmail: john@example.com\\nPhone: (555) 123-4567"
     }'
```

### Batch Processing
```bash
curl -X POST "http://localhost:8000/process-batch" \
     -H "Content-Type: application/json" \
     -d '{
       "texts": ["Text 1", "Text 2", "Text 3"],
       "tasks": ["entities", "classification"]
     }'
```

## üíª Python Integration

```python
from entity_extractor import EntityExtractor
from classifier import DataClassificationPipeline

# Initialize components
entity_extractor = EntityExtractor(languages=['en'])
classifier = DataClassificationPipeline()

# Extract entities
text = "John Smith lives at 123 Main St, email: john@example.com"
entities = entity_extractor.extract_all_entities(text)
print(f"Found {sum(len(v) for v in entities.values())} entities")

# Classify document
result = classifier.classify_data(text)
print(f"Document type: {result['classification_tasks']['document_type']['document_type']}")
```

## üß™ Testing

Run the comprehensive test suite:

```bash
python test_pipeline.py
```

Tests include:
- Entity extraction with various entity types
- Date and amount normalization
- Form field recognition
- Document classification
- Custom pattern matching
- Performance benchmarking

## üìä Example Outputs

### Entity Extraction
```json
{
  "entities": {
    "persons": [
      {"text": "John Smith", "confidence": 1.0, "source": "spacy"}
    ],
    "emails": [
      {"text": "john@example.com", "confidence": 0.9, "source": "pattern"}
    ],
    "phones": [
      {"text": "(555) 123-4567", "confidence": 0.9, "source": "pattern"}
    ],
    "addresses": [
      {"text": "123 Main St", "confidence": 0.8, "source": "pattern"}
    ]
  }
}
```

### Classification
```json
{
  "classification_results": {
    "document_type": {
      "document_type": "invoice",
      "confidence": 0.95
    },
    "sentiment": {
      "label": "NEUTRAL",
      "confidence": 0.85
    }
  }
}
```

### Form Fields
```json
{
  "form_structure": {
    "form_fields": {
      "name": {
        "value": "John Smith",
        "confidence": 0.9
      },
      "email": {
        "value": "john@example.com",
        "confidence": 0.95
      }
    },
    "total_fields": 2,
    "confidence_score": 0.925
  }
}
```

## üèóÔ∏è Architecture

```
code/nlp_pipeline/
‚îú‚îÄ‚îÄ main.py                 # FastAPI server and endpoints
‚îú‚îÄ‚îÄ entity_extractor.py     # Entity extraction logic
‚îú‚îÄ‚îÄ classifier.py           # Classification models
‚îú‚îÄ‚îÄ config.py              # Configuration settings
‚îú‚îÄ‚îÄ test_pipeline.py       # Test suite
‚îú‚îÄ‚îÄ __init__.py            # Package initialization
‚îî‚îÄ‚îÄ requirements.txt       # Dependencies

docs/
‚îî‚îÄ‚îÄ nlp_implementation.md  # Detailed documentation
```

## üéØ Supported Entities

### Built-in Entities
- **Persons**: Names, people
- **Organizations**: Companies, institutions
- **Locations**: Cities, countries, addresses
- **Dates**: Various date formats
- **Amounts**: Monetary values with currencies
- **Contact**: Phone numbers, emails
- **Custom**: User-defined patterns

### Document Types
- **Invoice**: Bills, receipts
- **Contract**: Agreements, terms
- **Resume**: CV, employment docs
- **Form**: Applications, surveys
- **Report**: Analytics, summaries

## üîê Security Features

- Input validation and sanitization
- File type restrictions
- Rate limiting
- CORS configuration
- PII detection and masking
- Audit logging

## üìà Performance

### Benchmarks
- **Entity Extraction**: ~100ms per document
- **Classification**: ~200ms per document
- **Form Recognition**: ~50ms per form
- **Batch Processing**: 1000+ docs/minute

### Optimization
- Model caching in memory
- GPU acceleration support
- Async processing
- Batch operations
- Connection pooling

## üöÄ Deployment

### Docker
```dockerfile
FROM python:3.9-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
EXPOSE 8000
CMD ["python", "main.py"]
```

### Production
```bash
# Using gunicorn
gunicorn main:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

### Kubernetes
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nlp-pipeline
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nlp-pipeline
  template:
    spec:
      containers:
      - name: nlp-pipeline
        image: nlp-pipeline:latest
        ports:
        - containerPort: 8000
```

## üõ†Ô∏è Development

### Adding Custom Patterns
```python
# Add custom entity pattern
extractor.add_custom_pattern(
    'PRODUCT_CODE',
    r'[A-Z]{2}\d{4}',
    'Product codes like AB1234'
)
```

### Custom Classification
```python
# Extend classification tasks
result = classifier.classify_data(text, [
    'document_type',
    'sentiment', 
    'custom_task'
])
```

### Model Fine-tuning
```python
# Use custom models
classifier = DataClassificationPipeline({
    'text_model': 'path/to/your/model',
    'entity_model': 'path/to/entity/model'
})
```

## üìù Documentation

- **API Documentation**: http://localhost:8000/docs
- **Implementation Guide**: [docs/nlp_implementation.md](docs/nlp_implementation.md)
- **Configuration**: See `config.py`
- **Examples**: See `test_pipeline.py`

## ü§ù Contributing

1. Follow PEP 8 style guidelines
2. Add tests for new features
3. Update documentation
4. Test with multiple languages
5. Validate performance impact

## üìÑ License

MIT License - see LICENSE file for details.

## üÜò Support

- **Issues**: Submit detailed bug reports
- **Questions**: Check documentation first
- **Features**: Suggest enhancements
- **Performance**: Include benchmarks

## üîÑ Roadmap

- [ ] Multi-modal support (images, audio)
- [ ] Real-time streaming API
- [ ] Model fine-tuning interface
- [ ] GraphQL API
- [ ] Database integration
- [ ] Caching layer
- [ ] Load balancing
- [ ] A/B testing support

---

**Built with ‚ù§Ô∏è using spaCy, Transformers, and FastAPI**
